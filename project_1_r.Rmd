Libraries
```{r}
library(data.table)
library(ggplot2)
library(randomForest)
library(anytime) #Load library for date conversion
library(reshape2)
library(lattice)
library(ggvis)
library(rpart)
library(rpart.plot)
library(C50)
library(corrplot)
library(xgboost)
library(magrittr)
library(dplyr)
library(DataExplorer)
library(Matrix)
library(caret)
library(xgboost)
library(Metrics)
library(readr)
library(stringr)
library(car)
library(multiROC)
library(mlbench)
library(tidyverse)
library(devtools)
library(ggstatsplot)
library(ROCR)
library(OneR)
library(caTools)
library(mlr)
library(pROC)

```

Import raw dataset
```{r}
setwd("C:/Users/johnpk/OneDrive/NTNU old/Maskinl√¶ring/HIOF ML prosjekter")
ios_act_raw <- data.table(read.csv("ios_act_test.csv")) #Read data from file into a data table`
```

Prepare dataset
```{r}
ios_act<-ios_act_raw[,-c(1:4,12,13,17,21,25:47,49, 50:54)] #Remove columns with the sum of zero,time,std = zero
```
----------------------------------------------------
Data exploration
----------------------------------------------------
Statistics about the dataset
```{r}
str(ios_act_raw)
dim(ios_act_raw) #The number of rows and columns
colnames(ios_act_raw) #The column names
summary(ios_act_raw) #Some descriptive statistics about the raw dataset
summary(ios_act) #Some descriptive statistics about the dataset
attributes(ios_act_raw) #The column names and the row names (Rownames are numerical in this example)
duplicated(ios_act_raw) #Check for duplicate names
sum(is.na(ios_act_raw)) #Check for missing values
ios_act_raw[, colSums(ios_act_raw != 0)>0] #Check for columns where all values like zero
plot_missing(ios_act_raw)
plot_bar(ios_act_raw)
plot_histogram(ios_act_raw)
plot_histogram(ios_act)
plot_correlation(ios_act)
numberOfClasses <- length(unique(ios_act$activity))
ggplot(data=ios_act)
boxplot(ios_act$activity~ios_act$locationLatitude, data=ios_act, horizontal=T)
boxplot(ios_act$locationLongitude, data=ios_act, horizontal=T)
boxplot(ios_act$locationAltitude,horizontal=T)
boxplot(ios_act$locationSpeed,horizontal=T)
boxplot(ios_act$locationCourse,horizontal=T)
boxplot(ios_act$locationVerticalAccuracy,horizontal=T, main="Location Vertical Accuracy")
boxplot(ios_act$locationHorizontalAccuracy,horizontal=T)
boxplot(ios_act$accelerometerAccelerationX,horizontal=T)
boxplot(ios_act$accelerometerAccelerationY,horizontal=T)
boxplot(ios_act$accelerometerAccelerationZ,horizontal=T)
boxplot(ios_act$gyroRotationX,horizontal=T)
boxplot(ios_act$gyroRotationY,horizontal=T)
boxplot(ios_act$gyroRotationZ,horizontal=T)
boxplot(ios_act$magnetometerX,horizontal=T)
boxplot(ios_act$magnetometerY,horizontal=T)
boxplot(ios_act$magnetometerZ,horizontal=T)

ggbetweenstats(data = ios_act, outlier.tagging = TRUE, outlier.label = name)

sapply(ios_act, class)
```

Distribution of the individual predictors
```{r}
ios_act.mlt <- data.table::melt(ios_act_raw, id.vars="activity", measure.vars = c(1:16)) #Transform the columns into key and values
densityplot(~value|variable,data = ios_act.mlt, scales = list(x = list(relation = "free"), y = list(relation = "free")),adjust = 1.25, pch = "|", xlab = "Predictor")

```

Correlation between the predictors
```{r}
res=cor(ios_act.pred) #Compute a correlation matrix
corrplot(res, type="upper", order="hclust", tl.col = "black", tl.srt=45)
```
--------------------------------------------------------------------
                    Create training and test set
--------------------------------------------------------------------

Create training and test set
```{r}
#Randomize the observations
ios_act.pred<-ios_act[,-c(17)] #A dataset with only the predictors
smp_size<-floor(0.8*nrow(ios_act)) #Sett sample size to 80% of the observations
set.seed(123)
ios_act_ind<-sample(seq_len(nrow(ios_act)),size=smp_size) #Create a randmoized dataset
ios_act.train<-ios_act[ios_act_ind,] #Training dataset (80%)
ios_act.test<-ios_act[-ios_act_ind,] #Test dataset (20%)

ios_act.train.pred<-ios_act.train[,-c(17)] #A training dataset with only the predictors
ios_act.train.target<-ios_act.train[,c(17)] #A training dataset with only the target variable
ios_act.test.pred<-ios_act.test[,-c(17)] #A test dataset with only the predictors
ios_act.test.target<-ios_act.test[,c(17)] #A test dataset with only the target variable

#Numeric target variables
ios_act.train.targetnum <- as.numeric(ios_act.train$activity)
ios_act.test.targetnum <- as.numeric(ios_act.test$activity)

```

----------------------------------------------------------------------------------
                            Pre-process data
----------------------------------------------------------------------------------
General
```{r}
ios_act$activity<-factor(ios_act$activity) 
```

Dimension reduction
```{r}
ios_act.train.pca <- prcomp(ios_act.train.pred, center=TRUE, scale. = TRUE)
summary(ios_act.train.pca)
```

For C5.0
```{r}
ios_act.train.target$activity<-factor(ios_act.train.target$activity)

pred_centered_scaled <- preProcess(ios_act.train.pred, method=c("center", "scale"))
ios_act.train.pred_centsca <- predict(pred_centered_scaled, ios_act.train.pred) 

pred_centered_scaled_test <- preProcess(ios_act.test.pred, method=c("center", "scale"))
ios_act.test.pred_centsca <- predict(pred_centered_scaled_test, ios_act.test.pred) 

pcacomp = preProcess(ios_act.train.pred, method=c("BoxCox", "center", "scale", "pca"))  #Preprosess predictors and generate PCA
transformedPredPCATrain <- predict(pcacomp, ios_act.train.pred) 

#ethod=c("BoxCox", "center", "scale", "pca"))
pcacompTst = preProcess(ios_act.test.pred, method=c("BoxCox", "center", "scale", "pca"))  #Preprosess predictors and generate
transformedPredPCATest<-predict(pcacompTst, ios_act.test.pred) 
```

For Random Forest
```{r}
preprPredictors = preProcess(ios_act.train.pred, method=c("BoxCox", "center", "scale","pca")) #Preprosess the original predictors
transformedPredTrain <- predict(preprPredictors, ios_act.train.pred)
```

For XGBoost
```{r}

#One hot encoding
new_train_pred <- model.matrix(~.+0,data = ios_act.train[,-c("activity"),with=F])
new_test_pred <- model.matrix(~.+0,data = ios_act.test[,-c("activity"),with=F])

trainTarget <- as.numeric(as.factor(ios_act.train$activity))-1
testTarget <- as.numeric(as.factor(ios_act.test$activity))-1

# Convert into a DMatrix object
dtrain <- xgb.DMatrix(data = new_train_pred,label = trainTarget) 
dtest <- xgb.DMatrix(data = new_test_pred,label= testTarget)

cvxgbhyperparams <- list(booster = "gbtree", objective = "multi:softmax", num_class = 5)

xgbcv <- xgb.cv( params = cvxgbhyperparams, data = dtrain, nrounds = 100, nfold = 5, showsd = T, stratified = T, print.every.n = 10, early.stop.round = 20, maximize = F)


```



----------------------------------------------------------------------------------
                                     C5.0
----------------------------------------------------------------------------------
Train
```{r}
#Rule based
mC5.0 <- C5.0(ios_act.train.pred, ios_act.train.target$activity, rules = TRUE)
summary(mC5.0) #Review the output of the model

#Tree based
m_1C5.0 <- C5.0(ios_act.train.pred, ios_act.train.target$activity, rules = FALSE)
summary(m_1C5.0) #Review the output of the model

#Tree based with pre-processeding (center, scaled, BoxCox, PCA
m_2C5.0 <- C5.0(ios_act.train.pred_centsca, ios_act.train.target$activity, rules = TRUE)
summary(m_2C5.0) #Review the output of the model

#Calculate costs of misclassification
cost_mat <- matrix(c(
  0,1,3,5,5,
  1,0,3,5,5,
  3,3,0,1,3,
  3,3,1,0,3,
  3,3,5,5,0
  ),5,5)

rownames(cost_mat) <- colnames(cost_mat) <- c("1","2","4","8","32")
cost_mat

m_3C5.0 <- C5.0(ios_act.train.pred, as.factor(ios_act.train.target$activity), trials=10, costs=cost_mat)
summary(m_3C5.0) #Review the output of the model

m_4C5.0 <- C5.0(ios_act.train.pred, as.factor(ios_act.train.target$activity), trials=10, control = C5.0Control(winnow = TRUE))
summary(m_4C5.0)
```

Predict
```{r}
mpC5.0<-predict(mC5.0, ios_act.test) #Run the prediction
mpC5.0prob<-predict(mC5.0, ios_act.test, type="prob") #Run the prediction

m_1pC5.0<-predict(m_1C5.0, ios_act.test) #Run the prediction
m_1pC5.0prob<-predict(m_1C5.0, ios_act.test, type="prob") #Run the prediction

m_2pC5.0<-predict(m_2C5.0, ios_act.test.pred_centsca) #Run the prediction

m_3pC5.0<-predict(m_3C5.0, ios_act.test) #Run the prediction

m_4pC5.0<-predict(m_4C5.0, ios_act.test) #Run the prediction

```

Evaluate
```{r}
confMatrixC5.0 <- confusionMatrix(table(mpC5.0, ios_act.test$activity),mode="everything")
tablempC5.0 <- confMatrixC5.0$table
accuracyC5.0 <- confMatrixC5.0$overall["Accuracy"]
kappaC5.0 <- confMatrixC5.0$overall["Kappa"]
F1C5.0 <- mean(confMatrixC5.0[["byClass"]][, "F1"])
ROCmpC5.0 <- multiclass.roc(response = ios_act.test$activity, predictor = predict(mC5.0, ios_act.test, type="prob"))

confMatrixC5.0_1 <- confusionMatrix(table(m_1pC5.0, ios_act.test$activity),mode="everything")
tablempC5.0_1 <- confMatrixC5.0_1$table
accuracyC5.0_1 <- confMatrixC5.0_1$overall["Accuracy"]
kappaC5.0_1 <- confMatrixC5.0_1$overall["Kappa"]
F1C5.0_1 <- mean(confMatrixC5.0_1[["byClass"]][, "F1"])
ROCmpC5.0_1 <- multiclass.roc(response = ios_act.test$activity, predictor = predict(m_1C5.0, ios_act.test, type="prob"))

confMatrixC5.0_2 <- confusionMatrix(table(m_2pC5.0, ios_act.test$activity),mode="everything")
tablempC5.0_2 <- confMatrixC5.0_2$table
accuracyC5.0_2 <- confMatrixC5.0_2$overall["Accuracy"]
kappaC5.0_2 <- confMatrixC5.0_2$overall["Kappa"]
F1C5.0_2 <- mean(confMatrixC5.0_2[["byClass"]][, "F1"])
ROCmpC5.0_2 <- multiclass.roc(response = ios_act.test$activity, predictor = predict(m_3C5.0, ios_act.test, type="prob"))

confMatrixC5.0_3 <- confusionMatrix(table(m_3pC5.0, ios_act.test$activity),mode="everything")
tablempC5.0_3 <- confMatrixC5.0_3$table
accuracyC5.0_3 <- confMatrixC5.0_3$overall["Accuracy"]
kappaC5.0_3 <- confMatrixC5.0_3$overall["Kappa"]
F1C5.0_3 <- mean(confMatrixC5.0_3[["byClass"]][, "F1"])
ROCmpC5.0_3 <- multiclass.roc(response = ios_act.test$activity, predictor = predict(m_2C5.0, ios_act.test, type="prob"))

confMatrixC5.0_4 <- confusionMatrix(table(m_4pC5.0, ios_act.test$activity),mode="everything")
tablempC5.0_4 <- confMatrixC5.0_4$table
accuracyC5.0_4 <- confMatrixC5.0_4$overall["Accuracy"]
kappaC5.0_4 <- confMatrixC5.0_4$overall["Kappa"]
F1C5.0_4 <- mean(confMatrixC5.0_4[["byClass"]][, "F1"])
ROCmpC5.0_4 <- multiclass.roc(response = ios_act.test$activity, predictor = predict(m_4C5.0, ios_act.test, type="prob"))

res <- multiclass.roc(response = ios_act.test$activity, predictor = predict(mC5.0, ios_act.test, type="prob"), force_diag=T)

plot(ROCmpC5.0$rocs)
plot(ROCmpC5.0, ylim=c(0,1), print.thres=TRUE, main=paste('AUC:',round(ROCmpC5.0$auc[[1]],4)))
abline(h=1,col='blue',lwd=2)
abline(h=0,col='red',lwd=2) 

n_method <- length(unique(res$Methods))
n_group <- length(unique(res$Groups))
res_df <- data.frame(Specificity= numeric(0), Sensitivity= numeric(0), Group = character(0), AUC = numeric(0), Method = character(0))
for (i in 1:n_method) {
      for (j in 1:n_group) {
        temp_data_1 <- data.frame(Specificity=res$Specificity[[i]][j],
                                  Sensitivity=res$Sensitivity[[i]][j],
                                  Group=unique(res$Groups)[j],
                                  AUC=res$AUC[[i]][j],
                                  Method = unique(res$Methods)[i])
        colnames(temp_data_1) <- c("Specificity", "Sensitivity", "Group", "AUC", "Method")
        res_df <- rbind(res_df, temp_data_1)

      }
      temp_data_2 <- data.frame(Specificity=res$Specificity[[i]][n_group+1],
                                Sensitivity=res$Sensitivity[[i]][n_group+1],
                                Group= "Macro",
                                AUC=res$AUC[[i]][n_group+1],
                                Method = unique(res$Methods)[i])
      temp_data_3 <- data.frame(Specificity=res$Specificity[[i]][n_group+2],
                                Sensitivity=res$Sensitivity[[i]][n_group+2],
                                Group= "Micro",
                                AUC=res$AUC[[i]][n_group+2],
                                Method = unique(res$Methods)[i])
      colnames(temp_data_2) <- c("Specificity", "Sensitivity", "Group", "AUC", "Method")
      colnames(temp_data_3) <- c("Specificity", "Sensitivity", "Group", "AUC", "Method")
      res_df <- rbind(res_df, temp_data_2)
      res_df <- rbind(res_df, temp_data_3)
    }



```
----------------------------------------------------------------------------------
                                Random forrest
----------------------------------------------------------------------------------
Train
```{r}
#(Standard values mtry=4 and number of trees = 500)
mRF<-randomForest(ios_act.train.pred, as.factor(ios_act.train.target$activity), importance = TRUE, na.action = na.omit)
mRF$confusion
summary(mRF)
print(mRF)
attributes(mRF) #Show the attributes of the model

table(ios_act.test$activity, mpRF)

#5 Repeats of 10 fold cross validation
tr <- trainControl(method = "cv", number = 5)
caret::train(y=as.factor(ios_act.train.target$activity), x=ios_act.train.pred, method="rf", trControl= tr)

m_1RF1<-randomForest(ios_act.train.pred, as.factor(ios_act.train.target$activity), mtry=10, importance = TRUE, na.action = na.omit)
m_1RF$confusion

#mtry changed after cross validation
mRF_1<-randomForest(ios_act.train.pred, as.factor(ios_act.train.target$activity), importance = TRUE, na.action = na.omit, mtry=9)
mRF_1$confusion #Confusing matrix for the modelsummary(m3.1)
summary(mRF_1)
print(mRF_1)
attributes(mRF_1) #Show the attributes of the model





```
 
Predict
```{r}
mpRF<-predict(mRF, ios_act.test, type = "response")
attributes(mpRF)

mpRF_1<-predict(mRF_1, ios_act.test, type = "response")
attributes(mpRF_1)

#m_2pC5.0<-predict(m_2C5.0, ios_act.test.pred_centsca) #Run the prediction

```

Evaluate
```{r}
confMatrixRF <- confusionMatrix(table(mpRF, ios_act.test$activity))

table(ios_act.test$activity, mpRF_1)

accuracyRF <- confMatrixRF$overall["Accuracy"]
kappaRF <- confMatrixRF$overall["Kappa"]
F1RF <- mean(confMatrixRF[["byClass"]][, "F1"])
ROCmpRF <- multiclass.roc(response = ios_act.test$activity, predictor = predict(mRF, ios_act.test, type="prob"))

confMatrixRF_1 <- confusionMatrix(table(mpRF_1, ios_act.test$activity))

table(ios_act.test$activity, mpRF_1)

accuracyRF <- confMatrixRF_1$overall["Accuracy"]
kappaRF <- confMatrixRF_1$overall["Kappa"]
F1RF <- mean(confMatrixRF_1[["byClass"]][, "F1"])
ROCmpRF <- multiclass.roc(response = ios_act.test$activity, predictor = predict(mRF_1, ios_act.test, type="prob"))


```
 
----------------------------------------------------------------------------------
                                    XGBoost
----------------------------------------------------------------------------------

Hyperparameters for Cross Validation
```{r}
cvxgbhyperparams <- list(booster = "gbtree", objective = "multi:softprob", num_class = 5, eval_metric = "mlogloss")
```

Run cross validation to imitigate overfitting. Finding the best nround value and estimate the test error
```{r}

xgbcv <- xgb.cv( params = cvxgbhyperparams, data = dtrain, nrounds = 100, nfold = 5, showsd = T, stratified = T, print.every.n = 10, early.stop.round = 20, maximize = F)

min(xgbcv$test.error.mean)

```

Function to compute the confusion matrix
```{r}
# Function to compute classification error
classification_error <- function(conf_mat) {
  conf_mat = as.matrix(conf_mat)
  
  error = 1 - sum(diag(conf_mat)) / sum(conf_mat)
  
  return (error)
}
```


Evaluate the cross validation
```{r}
# Mutate xgb output to deliver hard predictions
xgb_train_preds <- data.frame(xgbcv$pred) %>% mutate(max = max.col(., ties.method = "last"), label = ios_act.train.xgbtarget + 1)

# Examine output
head(xgb_train_preds)

# Confustion Matrix
xgb_conf_mat <- table(true = ios_act.train.xgbtarget + 1, pred = xgb_train_preds$max)

# Error 
cat("XGB Training Classification Error Rate:", classification_error(xgb_conf_mat), "\n")

xgb_conf_mat_2 <- confusionMatrix(factor(xgb_train_preds$label),
                                  factor(xgb_train_preds$max),
                                  mode = "everything")

print(xgb_conf_mat_2)

#Log loss, short for logarithmic loss is a loss function for classification that quantifies the price paid for the inaccuracy of predictions in classification problems. Log loss penalizes false classifications by taking into account the probability of classification.
min_logloss = min(xgbcv$evaluation_log[,c(test_mlogloss_mean)])
min_logloss_index = which.min(xgbcv$evaluation_log[,c(test_mlogloss_mean)]) #Find the index

   
```

Hyperparameters for the model
```{r}
xgbhyperparams <- list(booster = "gbtree", objective = "multi:softprob", "num_class" = 5, "eval_metric" = "mlogloss")
xgbhyperparams <- list(booster = "gbtree", objective = "multi:softprob", "num_class" = 4, "eval_metric" = "mlogloss") #Second dataset
xgbhyperparamsROC <- list(booster = "gbtree", objective = "multi:softmax", "num_class" = 5, "eval_metric" = "mlogloss")
xgbhyperparamsROC <- list(booster = "gbtree", objective = "multi:softmax", "num_class" = 4, "eval_metric" = "mlogloss")
```

Build the model
```{r}
#nrounds from xgb.cv
mXGB <- xgb.train (params = xgbhyperparams, data = dtrain, nrounds = 96)
mXGBROC <- xgb.train (params = xgbhyperparamsROC, data = dtrain, nrounds = 96)

```

Run the prediction
```{r}
mpXGB <- predict(mXGB, newdata = dtest)
mpXGBROC <- predict(mXGBROC, newdata = dtest)

```

Evaluate the model
```{r}
test_prediction <- matrix(mpXGB, nrow = numberOfClasses,
                          ncol=length(mpXGB)/numberOfClasses) %>%
  t() %>%
  data.frame() %>%
  mutate(label = testTarget + 1,
         max_prob = max.col(., "last"))



# confusion matrix of test set
xgbConfMatrix <- confusionMatrix(factor(test_prediction$max_prob),
                factor(test_prediction$label),
                mode = "everything")

accuracyXGB <- xgbConfMatrix$overall["Accuracy"]
kappaXGB <- xgbConfMatrix$overall["Kappa"]
F1XGB <- mean(xgbConfMatrix[["byClass"]][, "F1"])


ROCmpXGB <- multiclass.roc(response = testTarget, mpXGBROC)





```

-------------------------------------------------------------------------------
                           Functions
-------------------------------------------------------------------------------
```{r}


```
